# Day 7 R笔记

## Chapter 8 回归

### 1.OLS回归

拟合线性模型最基本的函数就是lm()，格式为：==myfit <- lm(*formula*, *data*)==

其中，*formula*指要拟合的模型形式，*data*是一个数据框，包含了用于拟合模型的数据。

表达式（formula）形式如下： Y ~ X1 + X2 + ... + Xk          ~左边为响应变量，右边为各个预测变量，预测变量之间用+符号分隔。

R表达式常用的符号见p162表8-2；可应用于拟合线性模型的其他函数见p162表8-3

* 简单线性回归：回归模型包含一个因变量和一个自变量

* 多项式回归：只有一个预测变量，但同时且包含变量的幂（比如，*X*、*X*^2^、*X*^3^）

* 多元线性回归:有不止一个预测变量

非线性模型可用nls()函数进行拟合。

car包中的scatterplot()函数，可以很容易、方便地绘制二元关系图。car包中scatterplotMatrix()函数则会生成散点图矩阵。scatterplotMatrix()函数默认在非对角线区域绘制变量间的散点图，并添加平滑和线性拟合曲线。对角线区域绘制每个变量的密度图和轴须图。

cor()函数提供了二变量之间的相关系数。

### 2.回归诊断

对lm()函数返回的对象使用plot()函数，可以生成评价模型拟合情况的四幅图形。

* 检验正态性：“正态Q-Q图”（Normal Q-Q）是在正态分布对应的值下，标准化残差的概 率图。若满足正态假设，那么图上的点应该落在呈45度角的直线上；若不是如此，那么就违反了正态性的假设。

* 检验独立性：逻辑先验

* 检验线性：残差值与预测（拟合）值没有任何系统关联，在“残差图与拟合图” （Residuals vs Fitted）中应无明显的曲线关系。

* 检验同方差：在“位置尺度图”（Scale-Location Graph，左下）中，水平线周围的点应该随机分布。

* “残差与杠杆图”（Residuals vs Leverage，右下）提供了你可能关注的单个观测点的信息。从图形可以鉴别出离群点、高杠杆值点和强影响点。

（**car**包中的）回归诊断实用函数见p175-176表8-4

* 检验正态性：qqPlot()函数提供了更为精确的正态假设检验方法，它画出了在*n*–*p*–1个自由度的t分布下的学生化残差（studentized residual，也称学生化删除残差或折叠 

  化残差）图形，其中*n*是样本大小，*p*是回归参数的数目（包括截距项）。代码如下： 

  library(car)  

  states <- as.data.frame(state.x77[,c("Murder", "Population",  

   "Illiteracy", "Income", "Frost")])  

  fit <- lm(Murder ~ Population + Illiteracy + Income + Frost, data=states)  

  ==qqPlot(==fit, labels=row.names(states), id.method="identify",  

   simulate=TRUE, main="Q-Q Plot"==)==

  id.method = "identify"选项能够交互式绘图—— 待图形绘制后，用鼠标单击图形内的点，将会标注函数中labels选项的设定值。敲击Esc键，从图形下拉菜单中选择Stop，或者在图形上右击，都将关闭这种交互模式

  可使用residplot()函数生成学生化残差柱状图（即直方图），并添加正态曲线、核密度曲线和轴须图。

* 检验误差的独立性：car包提供了一个可做Durbin-Watson检验的函数，能够检测误差的序列相关性。在多元回归中，使用下面的代码可以做Durbin-Watson检验： 

  \> durbinWatsonTest(fit) 

  p*值不显著说明无自相关性，误差项之间独立。滞后项（lag=1）表明数据集中每个数据都是与其后一个数据进行比较的。该检验适用于时间独立的数据，对于非聚集型的数据并不适用。注意，durbinWatsonTest()函数使用自助法（参见第12章）来导出*p*值。如果添加了选项simulate=TRUE，则每次运行测试时获得的结果都将略有不同。

* 检验线性：可用car包中的crPlots()函数绘制成分残差图

  \> library(car)  

  \> crPlots(fit)

  若图形存在非线性，则说明可能对预测变量的函数形式建模不够充分， 那么就需要添加一些曲线成分，比如多项式项，或对一个或多个变量进行变换（如用log(X)代 

  替X），或用其他回归变体形式而不是线性回归。

* 检验同方差性：car包提供了两个函数，可以判断误差方差是否恒定：

  1）ncvTest()函数生成一个计分检验，零假设为误差方差不变，备择假设为误差方差随着拟合值水平的变化而变化。若检验显著，则说明存在异方差性（误差方差不恒定）。

  2）spreadLevelPlot()函数创建一个添加了最佳拟合曲线的散点图，展示标准化残差绝对值与拟合值的关系。

* 线性模型假设的综合验证：gvlma包中的gvlma()函数。能对线性模型假设进行综合验证，同时还能做偏斜度、峰度和异方差性的评价。

  \> library(gvlma)  

  \> gvmodel <- gvlma(fit)  

  \> summary(gvmodel) 

* 检验多重共线性：多重共线性可用统计量VIF（Variance Inflation Factor，方差膨胀因子）进行检测。VIF的平方根表示变量回归参数的置信区间能膨胀为与模型无关的预测变量的程度。car包中的vif()函数提供VIF值。一般原则下， *vif* >2就表明存在多重共线性问题。

### 3.异常观测值诊断

* 离群点

  是指那些模型预测效果不佳的观测点。它们通常有很大的、或正或负的残差（*Y**i*–*Ŷ**i*）。正的残差说明模型低估了响应值，负的残差则说明高估了响应值。 

  car包也提供了一种离群点的统计检验方法。outlierTest()函数可以求得最大标准化残差绝对值Bonferroni调整后的*p*值： 

   \> library(car)  

   \> outlierTest(fit) 

* 高杠杆值点 

  高杠杆值观测点，即与其他预测变量有关的离群点。它们是由许多异常的预测变量值组合起来的，与响应变量值没有关系。高杠杆值的观测点可通过帽子统计量（hat statistic）判断。对于一个给定的数据集，帽子均值为*p*/*n*，其中*p*是模型估计的参数数目（包含截距项），*n*是样本量。一般来说，若观测点的帽子值大于帽子均值的2或3倍，就可以认定为高杠杆值点。

  ==hat.plot== <- function(fit) {  

   p <- length(coefficients(fit))  

   n <- length(fitted(fit))  

   plot(==hatvalues==(fit), main="Index Plot of Hat Values")  

   abline(h=c(2,3)*p/n, col="red", lty=2)  

   identify(1:n, hatvalues(fit), names(hatvalues(fit)))  

   }  

  hat.plot(fit)  

  高杠杆值点可能是强影响点，也可能不是，这要看它们是否是离群点。

* 强影响点 

  即对模型参数估计值影响有些比例失衡的点。有两种方法可以检测强影响点：

  1)Cook距离，或称D统计量

  一般来说，Cook’s D值大于4/(*n*–*k*–1)，则表明它是强影响点，其中*n*为样本量大小，*k*是预测变量数目。可通过如下代码绘制Cook’s D图形： 

  cutoff <- 4/(nrow(states)-length(fit$coefficients)-2)  

  plot(fit, which=4, cook.levels=cutoff)  

  abline(h=cutoff, lty=2, col="red") 

  2)变量添加图（added variable  plot）

  即对于每个预测变量*X**k*，绘制*X**k*在其他*k*–1个预测变量上回归的残差值相对于响应变量在其他*k*–1个预测变量上回归的残差值的关系图。car包中的==avPlots()==函数可提 

  供变量添加图： 

  library(car)  

  avPlots(fit, ask=FALSE, id.method="identify") 

### 4.改进措施

* 删除观测点

* 变量变换

  当模型不符合正态性、线性或者同方差性假设时，一个或多个变量的变换通常可以改善或调整模型效果。变换多用*Y*^λ^替代*Y*

  car包中的powerTransform() 函数通过*λ*的最大似然估计来正态化变量*X* ^λ^。

  car包中的boxTidwell()函数通过获得预测变量幂数的最大似然估计来改善线性关系。

* 增删变量

### 5.选择最佳的回归模型

* 模型比较

  1）用基础安装中的anova()函数可以比较两个嵌套模型的拟合优度。所谓嵌套模型，即它的一 些项完全包含在另一个模型中。

  在多元回归模型中，回归系数的自变量不显著，可以检验不含这两个变量的模型与包含这两项的模型预测效果是否一样好。如果检验不显著，我们可以得出结论：不需要将这两个变量添加到线性模型中，可以将它们从模型中删除，

  2）AIC（Akaike Information Criterion，赤池信息准则）也可以用来比较模型，它考虑了模型的统计拟合度以及用来拟合的参数数目。AIC值较小的模型要优先选择，它说明模型用较少的参数获得了足够的拟合度。该准则可用AIC()函数实现

* 变量选择

  1）逐步回归 

  逐步回归中，模型会一次添加或者删除一个变量，直到达到某个判停准则为止。例如，向前 逐步回归（forward stepwise regression）每次添加一个预测变量到模型中，直到添加变量不会使模型有所改进为止。向后逐步回归（backward stepwise regression）从模型包含所有预测变量开始，一次删除一个变量直到会降低模型质量为止。而向前向后逐步回归（stepwise stepwise regression，通常称作逐步回归，以避免听起来太冗长），结合了向前逐步回归和向后逐步回归的方法，变量每次进入一个，但是每一步中，变量都会被重新评价，对模型没有贡献的变量将会被删除，预测变量可能会被添加、删除好几次，直到获得最优模型为止。 

  逐步回归法的实现依据增删变量的准则不同而不同。MASS包中的==stepAIC()==函数可以实现逐步回归模型（向前、向后和向前向后），依据的是精确AIC准则。

  2)全子集回归

  可用leaps包中的==regsubsets()==函数实现。能通过R平方、调整R平方或Mallows Cp统计量等准则来选择“最佳”模型。 

  R平方含义是预测变量解释响应变量的程度；调整R平方与之类似，但考虑了模型的参数数 目。R平方总会随着变量数目的增加而增加。当与样本量相比，预测变量数目很大时，容易导致 过拟合。R平方很可能会丢失数据的偶然变异信息，而调整R平方则提供了更为真实的R平方估计。

### 6.深层次分析

* 交叉验证

  即将一定比例的数据挑选出来作为训练样本，另外的样本作保留样本，先在训练样本上获取回归方程，然后在保留样本上做预测。在*k*重交叉验证中，样本被分为*k*个子样本，轮流将*k*–1个子样本组合作为训练集，另外1个子样本作为保留集。这样会获得*k*个预测方程，记录*k*个保留样本的预测表现结果，然后求其平均值。（当*n*是观测总数目，且*k*为*n*时，该方法又称作刀切法，jackknifing。） bootstrap 包中的 ==crossval()==函数可以实现 *k* 重交叉验证。

* 变量的相对重要性

